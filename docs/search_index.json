[["index.html", "Análise de Regressão - uma introdução 1 Exemplo : Estatura e Massa Corporal", " Análise de Regressão - uma introdução Prof. Iuri Ferreira 24 de fevereiro de 2022 1 Exemplo : Estatura e Massa Corporal Dados de peso e altura peso &lt;- c( 78, 65, 57, 89, 74, 68, 77, 95, 86, 72, 63, 85, 69 ) altura &lt;- c( 1.64, 1.65, 1.56, 1.87, 1.63, 1.70, 1.72, 1.88, 1.75, 1.67, 1.59, 1.80, 1.64) df &lt;- data.frame(peso, altura) head(df) ## peso altura ## 1 78 1.64 ## 2 65 1.65 ## 3 57 1.56 ## 4 89 1.87 ## 5 74 1.63 ## 6 68 1.70 Diagrama de dispersão plot(peso, altura, xlab = &quot;Massa corpórea (kg)&quot;, ylab = &quot;Estatura (m)&quot;, cex.lab=1.3) Questões: A relação é aproximadamente linear? A relação é positiva ou negativa? A relação é forte ou fraca? Existem outliers? "],["covariância-e-correlação.html", " 2 Covariância e Correlação", " 2 Covariância e Correlação Aspectos teóricos na aula abaixo: "],["correlação-linear.html", " 3 Correlação Linear", " 3 Correlação Linear Covariância cov(peso, altura) ## [1] 1.020833 Correlação Linear de Pearson (\\(r\\)) cor(peso, altura) ## [1] 0.9101177 Coeficiente de Determinação (\\(R^2\\) %) 100*cor(peso, altura)^2 ## [1] 82.83142 Teste t para a correlação linear cor.test(peso, altura) ## ## Pearson&#39;s product-moment correlation ## ## data: peso and altura ## t = 7.285, df = 11, p-value = 1.573e-05 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7203704 0.9731205 ## sample estimates: ## cor ## 0.9101177 Entendendo o teste t_cal &lt;- 7.285 # t calculado n_df &lt;- 11 # número de graus de liberdade t_crit_1 &lt;- qt(0.025, df = 11) t_crit_2 &lt;- qt(0.975, df = 11) # gráfico da distribuição de teste curve( dt(x, df = n_df), -10, 10, lwd = 2, ylab = &quot;Densidade t&quot;, xlab = &quot;Valores de t&quot; ) abline( v = t_crit_1, lty = 2, col = 2, lwd = 3) abline( v = t_crit_2, lty = 2, col = 2, lwd = 3) points(t_cal, 0 , pch = 19, cex = 3) "],["associações-não-lineares.html", " 4 Associações não-lineares", " 4 Associações não-lineares Imaginem um experimento de química, em que as variáveis sejam a concentração de substrato (mg/L) e a velocidade de reação (mg/min.L). Os dados ilustrativos seguem abaixo: x &lt;- c(0.1, 0.5, 1, 2, 4, 8, 16) y &lt;- c(0.1, 0.4, 0.8, 1.4, 2, 2.34, 2.45) df2 &lt;- data.frame(x, y) O gráfico dos resultados do experimento está dispoto a seguir plot(df2$x, df2$y, xlab = &quot;Reagente&quot;, ylab = &quot;Velocidade&quot;, cex = 1.3, pch =19, type = &quot;b&quot;, cex.lab =1.5) "],["coeficiente-de-spearman-rho.html", " 5 Coeficiente de Spearman (\\(\\rho\\))", " 5 Coeficiente de Spearman (\\(\\rho\\)) Para relações não-lineares o coeficiente de Pearson é inadequado O coeficiente de Spearman mede a correlação entre postos (ranks) Se as observações apresentam uma relação perfeita, eu espero que: o menor valor de x esteja com o menor valor de y; o 2º menor valor de x esteja com o 2º menor valor de y; e, assim, por diante  Correlação de Spearman. Fonte: wikpedia Agora vamos cacular a correlação de Spearman no R cor(df2$x, df2$y, method = &quot;spearman&quot;) ## [1] 1 Para o nosso banco de dados, a correlação de Spearman é perfeita. Isso significa que a velocidade de reação e a quantidade de reagentes são perfeitamentes relacionados através de uma curva monótona. No caso, a associação é positiva (curva crescente). Teste para a correlação de Spearman cor.test(df2$x, df2$y, method = &quot;spearman&quot;) ## ## Spearman&#39;s rank correlation rho ## ## data: df2$x and df2$y ## S = 1.2434e-14, p-value = 0.0003968 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 1 "],["modelos-de-regressão.html", " 6 Modelos de Regressão 6.1 Modelos lineares 6.2 Modelo Linear - Forma Geral 6.3 Exercícios", " 6 Modelos de Regressão Em muitas circunstâncias, tratamos uma variável como resposta (dependente) e outra como explicação (independente) Então, a variável Y pode ser representada por uma função de X Podemos escrever que \\[ \\Large y_i = f(x_i) + \\epsilon_i \\] Em que: O \\(y_i\\) é a resposta medida na unidade i \\((i = 1, 2, \\cdots, n)\\); O \\(x_i\\) é a variável explicativa/regressora medida na unidade i; O \\(\\epsilon_i\\) é o erro aleatório intrínseco à unidade i. 6.1 Modelos lineares Um modelo simples seria uma reta \\[ \\Large y_i = \\beta_0 + \\beta_1 \\, x_i + \\epsilon_i \\] Aqui o parâmetro \\(\\beta_0\\) é o intercepto, onde a reta cruza o eixo \\(y\\) E o parâmetro \\(\\beta_1\\) é a inclinação (ou efeito) Em Estatística, o modelo quadrático também é linear \\[ \\Large y_i = \\beta_0 + \\beta_1 \\, x_i + \\beta_2 \\, x^2_i + \\epsilon_i \\] Mas como assim? Linear não é necessariamente reta; Isso significa que os parâmetros são linearmente dispostos no modelo; Ou seja, se derivarmos a função com respeito aos parâmetros, o resultado independe deles: \\[ \\frac{\\partial f}{\\partial \\beta_0} ~~ \\mbox{não depende de} ~~ \\beta_0 \\] \\[ \\frac{\\partial f}{\\partial \\beta_1} ~~ \\mbox{não depende de} ~~ \\beta_1 \\] \\[ \\frac{\\partial f}{\\partial \\beta_2} ~~ \\mbox{não depende de} ~~ \\beta_2 \\] Quando isso ocorre, é ótimo!!! Choramos de felicidade!!! Os modelos lineares possuem propriedades excelentes 6.2 Modelo Linear - Forma Geral Os modelos lineares podem ser descritos por: \\[ \\Large f(x_i) = \\sum_{j = 0}^{p} \\beta_j \\, \\phi_j (x_i) \\] Ou seja \\[ \\Large f(x_i) = \\beta_0 \\, \\phi_0 (x_i) + \\beta_1 \\, \\phi_1 (x_i) + \\cdots + \\beta_p \\, \\phi_p (x_i) \\] Em que as funções \\(\\phi_j\\) não dependem de parâmetros livres (valores desconhecidos, a serem estimados a partir dos dados) - no caso os betas! Ao ajustar um modelo linear, temos que calcular seus \\(p + 1\\) parâmetros livres a partir da informação dos dados. 6.3 Exercícios Determine as funções \\(\\phi_j\\) para o modelo linear de 1º grau: \\[ \\Large y_i = \\beta_0 + \\beta_1 \\, x_i + \\epsilon_i \\] O modelo abaixo é linear? Explique o por quê? \\[ \\Large y_i = \\beta_0 + \\beta_1 \\, e^{x_i} + \\beta_2 \\, \\sin(10 x_i^2 \\pi ) + \\epsilon_i \\] E o que dizer do modelo de Michaelis-Menten? \\[ \\Large y_i = \\frac{\\beta_0 \\, x_i}{\\beta_2 + x_i} + \\epsilon_i \\] E para o modelo a seguir, a duas variáveis explicativas? \\[ \\Large y = \\beta_0 + \\beta_1 \\, x_1 + \\beta_{11} \\, x_1^2 + \\beta_2 \\, x_2 + \\beta_{22} \\, x_2^2 + \\beta_{12} x_1 \\, x_2 + \\epsilon \\] Este é o modelo polinomial de segundo grau completo para experimentos com duas variáveis quantitativas. "],["prática-computacional.html", " 7 Prática Computacional 7.1 Ajuste de reta 7.2 Ajuste não-linear", " 7 Prática Computacional 7.1 Ajuste de reta Os dados do exemplo 1 já estão gravados na memória do computador. Vamos gerar um ajuste linear: O ajuste é gerado com a função lm, o resultado é analisado a partir do comando summary e o gráfico é plotado com os comandos plot e coef, que nos dá os coeficientes do modelo ajustado. nosso_ajuste &lt;- lm(altura ~ peso) summary(nosso_ajuste) ## ## Call: ## lm(formula = altura ~ peso) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.082732 -0.009601 0.005477 0.019807 0.059356 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.082448 0.085626 12.642 6.80e-08 *** ## peso 0.008209 0.001127 7.285 1.57e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.04353 on 11 degrees of freedom ## Multiple R-squared: 0.8283, Adjusted R-squared: 0.8127 ## F-statistic: 53.07 on 1 and 11 DF, p-value: 1.573e-05 plot(peso, altura, xlab = &quot;Massa corpórea (kg)&quot;, ylab = &quot;Estatura (m)&quot;, cex.lab=1.3) abline(coef(nosso_ajuste), col = 2, lwd = 3, lty = 2) Mas este comando corresponde à qual equação? Usamos o pacote equatiomatic para saber a equação! # Install.packages(&quot;equatiomatic&quot;) library(equatiomatic) ## Warning: package &#39;equatiomatic&#39; was built under R version 4.1.2 extract_eq(nosso_ajuste) \\[ \\operatorname{altura} = \\alpha + \\beta_{1}(\\operatorname{peso}) + \\epsilon \\] Ok! Mas como obter os valores preditos a partir da fórmula? extract_eq(nosso_ajuste, wrap = TRUE, use_coefs = TRUE) \\[ \\begin{aligned} \\operatorname{\\widehat{altura}} &amp;= 1.08 + 0.01(\\operatorname{peso}) \\end{aligned} \\] E vocês sabiam que dá para fazer ANOVA para o ajuste de curvas? anova(nosso_ajuste) ## Analysis of Variance Table ## ## Response: altura ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## peso 1 0.100557 0.100557 53.071 1.573e-05 *** ## Residuals 11 0.020843 0.001895 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 E será que o ajuste ficou bom? Vamos olhar para o coeficiente de determinação. summary( nosso_ajuste )$r.squared ## [1] 0.8283142 Ok! A variável massa corporal explica 82,8% da variação observada na variável estatura. Será que os pontos são bem explicados pela reta. Vamos olhar os resíduos. Independência e tendências não capturadas pelo modelo plot(fitted(nosso_ajuste), rstandard(nosso_ajuste), ylab = &quot;Resíduos padronizados&quot;, xlab = &quot;Valores ajustados&quot;, ylim = c(-4, 4)) + abline(h = 0, lty =2) ## integer(0) Gráfico Quantil-Quantil # install.packages(&quot;car&quot;) library(car) ## Carregando pacotes exigidos: carData qqPlot(nosso_ajuste) ## [1] 1 4 7.2 Ajuste não-linear Nesse caso, o comando lm já não funciona mais. Vou explicar melhor adiante! Vamos usar o procedimento iterativo (Gauss-Newton) de estimação do pacote nls michaelis_fit &lt;- nls( y ~ a*x / (b + x) , data = df2, start = list(a = 4, b = 4) ) Nesse caso, a e b são valores desconhecidos - parâmetros Foi necessário chutar valores iniciais para obter o ajuste O resumo do ajuste é dado por: summary( michaelis_fit ) ## ## Formula: y ~ a * x/(b + x) ## ## Parameters: ## Estimate Std. Error t value Pr(&gt;|t|) ## a 2.9318 0.1432 20.481 5.14e-06 *** ## b 2.2936 0.3431 6.686 0.00113 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1103 on 5 degrees of freedom ## ## Number of iterations to convergence: 6 ## Achieved convergence tolerance: 4.491e-06 O resultado do ajuste foi: plot(x, y, xlab = &quot;Reagente&quot;, ylab = &quot;Velocidade&quot;) z &lt;- seq(0, 16, by = 0.1) y_fit &lt;- predict(michaelis_fit, newdata = data.frame(x = z), type = &quot;response&quot;) lines(z , y_fit, lwd =2, col = 2, lty = 2) "],["references.html", "References", " References "]]
